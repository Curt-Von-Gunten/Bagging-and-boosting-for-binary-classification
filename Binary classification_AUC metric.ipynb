{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook stuff\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "\n",
    "#Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#Model evaluation, selection, metrics, and saving.\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#schikit models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, Ridge, Lasso, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a copy.\n",
    "train_copy = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,2:]\n",
    "y = train.iloc[:,1]\n",
    "#X.shape\n",
    "#X.head()\n",
    "#y.shape\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape\n",
    "#X_test.shape\n",
    "#y_train.shape\n",
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('quantiletransformer', QuantileTransformer(copy=True, ignore_implicit_zeros=False, n_quantiles=1000,\n",
       "          output_distribution='normal', random_state=None,\n",
       "          subsample=100000)), ('gaussiannb', GaussianNB(priors=None))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "#############Code for Naive Bayes###################\n",
    "pipeline = make_pipeline(QuantileTransformer(output_distribution='normal'), GaussianNB())\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8894234103828369"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 70, 130, 190, 250],\n",
       " 'max_features': ['sqrt', 'log2'],\n",
       " 'max_depth': [5, 17, 30, 42, 55],\n",
       " 'min_samples_split': [5, 10, 20, 50, 100],\n",
       " 'min_samples_leaf': [5, 10, 20, 50, 100, 200, 300],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "########################################Random Forest#####################################################\n",
    "#############Performing random grid search for random forest, for all variables, unstandardized, using the AUC metric###############\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "#Tuning the hyperparameters of Forest \n",
    "#Grid from here: (https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)\n",
    "#I modified the values quite a bit.\n",
    "#Also see: https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 250, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 55, num = 5)]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 20, 50, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [5, 10, 20, 50, 100, 200, 300]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "display(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "score = 'roc_auc'\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, cv = 4, scoring = score, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_score_\n",
    "rf_random.best_params_\n",
    "#rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [500, 750],\n",
       " 'max_features': [5, 'log2'],\n",
       " 'max_depth': [55, 75],\n",
       " 'min_samples_split': [20],\n",
       " 'min_samples_leaf': [2, 5, 10],\n",
       " 'bootstrap': [True]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tuning the hyperparameters of Forest using grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [500,750]\n",
    "# Number of features to consider at every split\n",
    "max_features = [5,'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [55,75]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2,5,10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 77.4min\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 138.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [500, 750], 'max_features': [5, 'log2'], 'max_depth': [55, 75], 'min_samples_split': [20], 'min_samples_leaf': [2, 5, 10], 'bootstrap': [True]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search.\n",
    "score = 'roc_auc'\n",
    "rf = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                       cv = 2, n_jobs = -1, verbose = 2, scoring = score)\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728381794677282"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 75,\n",
       " 'max_features': 5,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 20,\n",
       " 'n_estimators': 750}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=75, max_features=5, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=750, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_score_\n",
    "rf_grid.best_params_\n",
    "#rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1188.121302</td>\n",
       "      <td>4.090624</td>\n",
       "      <td>23.246833</td>\n",
       "      <td>0.053401</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.871465</td>\n",
       "      <td>0.874211</td>\n",
       "      <td>0.872838</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>5.028113e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1171.808834</td>\n",
       "      <td>9.128552</td>\n",
       "      <td>23.502392</td>\n",
       "      <td>0.069870</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.869520</td>\n",
       "      <td>0.874596</td>\n",
       "      <td>0.872058</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>3.661838e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>788.493998</td>\n",
       "      <td>8.228735</td>\n",
       "      <td>15.833131</td>\n",
       "      <td>0.247540</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.868902</td>\n",
       "      <td>0.873614</td>\n",
       "      <td>0.871258</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>3.529083e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>802.589767</td>\n",
       "      <td>3.664433</td>\n",
       "      <td>15.735285</td>\n",
       "      <td>0.138742</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.869426</td>\n",
       "      <td>0.872270</td>\n",
       "      <td>0.870848</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>6.781592e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1282.170920</td>\n",
       "      <td>6.498678</td>\n",
       "      <td>24.927966</td>\n",
       "      <td>0.083598</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.869149</td>\n",
       "      <td>0.872466</td>\n",
       "      <td>0.870808</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.425182e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242.880284</td>\n",
       "      <td>10.224535</td>\n",
       "      <td>25.404377</td>\n",
       "      <td>0.364822</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.869142</td>\n",
       "      <td>0.872150</td>\n",
       "      <td>0.870646</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.978330e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>826.366044</td>\n",
       "      <td>1.867286</td>\n",
       "      <td>17.262984</td>\n",
       "      <td>0.169685</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.867893</td>\n",
       "      <td>0.869358</td>\n",
       "      <td>0.868626</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.522810e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>851.876784</td>\n",
       "      <td>7.341622</td>\n",
       "      <td>16.912356</td>\n",
       "      <td>0.376052</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.867131</td>\n",
       "      <td>0.869501</td>\n",
       "      <td>0.868316</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.467495e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1276.523667</td>\n",
       "      <td>20.226698</td>\n",
       "      <td>17.164868</td>\n",
       "      <td>0.199389</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.865134</td>\n",
       "      <td>0.869452</td>\n",
       "      <td>0.867293</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>2.594263e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1408.033100</td>\n",
       "      <td>9.402028</td>\n",
       "      <td>27.385655</td>\n",
       "      <td>0.125768</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.866001</td>\n",
       "      <td>0.867989</td>\n",
       "      <td>0.866995</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1711.060201</td>\n",
       "      <td>19.052866</td>\n",
       "      <td>23.642362</td>\n",
       "      <td>0.126515</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.864514</td>\n",
       "      <td>0.868633</td>\n",
       "      <td>0.866573</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>11</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>2.986998e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1355.365390</td>\n",
       "      <td>14.466415</td>\n",
       "      <td>27.483272</td>\n",
       "      <td>0.892096</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.865679</td>\n",
       "      <td>0.867220</td>\n",
       "      <td>0.866449</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.425182e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1713.320399</td>\n",
       "      <td>11.163297</td>\n",
       "      <td>19.453864</td>\n",
       "      <td>0.141736</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.863348</td>\n",
       "      <td>0.867451</td>\n",
       "      <td>0.865400</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>13</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>5.221715e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1077.819638</td>\n",
       "      <td>3.875316</td>\n",
       "      <td>13.720266</td>\n",
       "      <td>0.045665</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.862625</td>\n",
       "      <td>0.867951</td>\n",
       "      <td>0.865288</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>14</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>8.075957e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1818.673614</td>\n",
       "      <td>22.586803</td>\n",
       "      <td>25.583010</td>\n",
       "      <td>0.419222</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.863130</td>\n",
       "      <td>0.867004</td>\n",
       "      <td>0.865067</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>15</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2.710424e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1118.381153</td>\n",
       "      <td>16.508605</td>\n",
       "      <td>15.714832</td>\n",
       "      <td>0.043419</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.862539</td>\n",
       "      <td>0.867335</td>\n",
       "      <td>0.864937</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>16</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>5.028113e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>931.819528</td>\n",
       "      <td>10.390441</td>\n",
       "      <td>17.835137</td>\n",
       "      <td>0.028198</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.863306</td>\n",
       "      <td>0.865409</td>\n",
       "      <td>0.864357</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.765739e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900.659511</td>\n",
       "      <td>11.891447</td>\n",
       "      <td>18.107667</td>\n",
       "      <td>0.237310</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.863584</td>\n",
       "      <td>0.864962</td>\n",
       "      <td>0.864273</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.106295e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1206.674889</td>\n",
       "      <td>8.756973</td>\n",
       "      <td>16.483139</td>\n",
       "      <td>0.092578</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.862129</td>\n",
       "      <td>0.866089</td>\n",
       "      <td>0.864109</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>19</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.814325e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1207.098048</td>\n",
       "      <td>15.833856</td>\n",
       "      <td>16.577736</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.861740</td>\n",
       "      <td>0.865444</td>\n",
       "      <td>0.863592</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>20</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.216925e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1997.866520</td>\n",
       "      <td>19.412149</td>\n",
       "      <td>26.208069</td>\n",
       "      <td>0.701946</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.859820</td>\n",
       "      <td>0.862145</td>\n",
       "      <td>0.860982</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1975.088784</td>\n",
       "      <td>14.781049</td>\n",
       "      <td>27.181299</td>\n",
       "      <td>0.103559</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>750</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.858944</td>\n",
       "      <td>0.861800</td>\n",
       "      <td>0.860372</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.476163e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1343.829424</td>\n",
       "      <td>8.620715</td>\n",
       "      <td>18.081669</td>\n",
       "      <td>0.173428</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 75, 'max_feat...</td>\n",
       "      <td>0.858792</td>\n",
       "      <td>0.861158</td>\n",
       "      <td>0.859975</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.531477e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1316.177200</td>\n",
       "      <td>5.852634</td>\n",
       "      <td>17.910764</td>\n",
       "      <td>0.251031</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 55, 'max_feat...</td>\n",
       "      <td>0.858496</td>\n",
       "      <td>0.860777</td>\n",
       "      <td>0.859637</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.650775e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "17    1188.121302      4.090624        23.246833        0.053401   \n",
       "5     1171.808834      9.128552        23.502392        0.069870   \n",
       "4      788.493998      8.228735        15.833131        0.247540   \n",
       "16     802.589767      3.664433        15.735285        0.138742   \n",
       "15    1282.170920      6.498678        24.927966        0.083598   \n",
       "3     1242.880284     10.224535        25.404377        0.364822   \n",
       "2      826.366044      1.867286        17.262984        0.169685   \n",
       "14     851.876784      7.341622        16.912356        0.376052   \n",
       "23    1276.523667     20.226698        17.164868        0.199389   \n",
       "13    1408.033100      9.402028        27.385655        0.125768   \n",
       "11    1711.060201     19.052866        23.642362        0.126515   \n",
       "1     1355.365390     14.466415        27.483272        0.892096   \n",
       "21    1713.320399     11.163297        19.453864        0.141736   \n",
       "22    1077.819638      3.875316        13.720266        0.045665   \n",
       "9     1818.673614     22.586803        25.583010        0.419222   \n",
       "10    1118.381153     16.508605        15.714832        0.043419   \n",
       "12     931.819528     10.390441        17.835137        0.028198   \n",
       "0      900.659511     11.891447        18.107667        0.237310   \n",
       "20    1206.674889      8.756973        16.483139        0.092578   \n",
       "8     1207.098048     15.833856        16.577736        0.012976   \n",
       "19    1997.866520     19.412149        26.208069        0.701946   \n",
       "7     1975.088784     14.781049        27.181299        0.103559   \n",
       "18    1343.829424      8.620715        18.081669        0.173428   \n",
       "6     1316.177200      5.852634        17.910764        0.251031   \n",
       "\n",
       "   param_bootstrap param_max_depth param_max_features param_min_samples_leaf  \\\n",
       "17            True              75                  5                     10   \n",
       "5             True              55                  5                     10   \n",
       "4             True              55                  5                     10   \n",
       "16            True              75                  5                     10   \n",
       "15            True              75                  5                      5   \n",
       "3             True              55                  5                      5   \n",
       "2             True              55                  5                      5   \n",
       "14            True              75                  5                      5   \n",
       "23            True              75               log2                     10   \n",
       "13            True              75                  5                      2   \n",
       "11            True              55               log2                     10   \n",
       "1             True              55                  5                      2   \n",
       "21            True              75               log2                      5   \n",
       "22            True              75               log2                     10   \n",
       "9             True              55               log2                      5   \n",
       "10            True              55               log2                     10   \n",
       "12            True              75                  5                      2   \n",
       "0             True              55                  5                      2   \n",
       "20            True              75               log2                      5   \n",
       "8             True              55               log2                      5   \n",
       "19            True              75               log2                      2   \n",
       "7             True              55               log2                      2   \n",
       "18            True              75               log2                      2   \n",
       "6             True              55               log2                      2   \n",
       "\n",
       "   param_min_samples_split param_n_estimators  \\\n",
       "17                      20                750   \n",
       "5                       20                750   \n",
       "4                       20                500   \n",
       "16                      20                500   \n",
       "15                      20                750   \n",
       "3                       20                750   \n",
       "2                       20                500   \n",
       "14                      20                500   \n",
       "23                      20                750   \n",
       "13                      20                750   \n",
       "11                      20                750   \n",
       "1                       20                750   \n",
       "21                      20                750   \n",
       "22                      20                500   \n",
       "9                       20                750   \n",
       "10                      20                500   \n",
       "12                      20                500   \n",
       "0                       20                500   \n",
       "20                      20                500   \n",
       "8                       20                500   \n",
       "19                      20                750   \n",
       "7                       20                750   \n",
       "18                      20                500   \n",
       "6                       20                500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "17  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.871465   \n",
       "5   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.869520   \n",
       "4   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.868902   \n",
       "16  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.869426   \n",
       "15  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.869149   \n",
       "3   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.869142   \n",
       "2   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.867893   \n",
       "14  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.867131   \n",
       "23  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.865134   \n",
       "13  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.866001   \n",
       "11  {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.864514   \n",
       "1   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.865679   \n",
       "21  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.863348   \n",
       "22  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.862625   \n",
       "9   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.863130   \n",
       "10  {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.862539   \n",
       "12  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.863306   \n",
       "0   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.863584   \n",
       "20  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.862129   \n",
       "8   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.861740   \n",
       "19  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.859820   \n",
       "7   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.858944   \n",
       "18  {'bootstrap': True, 'max_depth': 75, 'max_feat...           0.858792   \n",
       "6   {'bootstrap': True, 'max_depth': 55, 'max_feat...           0.858496   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "17           0.874211         0.872838        0.001373                1   \n",
       "5            0.874596         0.872058        0.002538                2   \n",
       "4            0.873614         0.871258        0.002356                3   \n",
       "16           0.872270         0.870848        0.001422                4   \n",
       "15           0.872466         0.870808        0.001659                5   \n",
       "3            0.872150         0.870646        0.001504                6   \n",
       "2            0.869358         0.868626        0.000732                7   \n",
       "14           0.869501         0.868316        0.001185                8   \n",
       "23           0.869452         0.867293        0.002159                9   \n",
       "13           0.867989         0.866995        0.000994               10   \n",
       "11           0.868633         0.866573        0.002059               11   \n",
       "1            0.867220         0.866449        0.000770               12   \n",
       "21           0.867451         0.865400        0.002052               13   \n",
       "22           0.867951         0.865288        0.002663               14   \n",
       "9            0.867004         0.865067        0.001937               15   \n",
       "10           0.867335         0.864937        0.002398               16   \n",
       "12           0.865409         0.864357        0.001051               17   \n",
       "0            0.864962         0.864273        0.000689               18   \n",
       "20           0.866089         0.864109        0.001980               19   \n",
       "8            0.865444         0.863592        0.001852               20   \n",
       "19           0.862145         0.860982        0.001162               21   \n",
       "7            0.861800         0.860372        0.001428               22   \n",
       "18           0.861158         0.859975        0.001183               23   \n",
       "6            0.860777         0.859637        0.001141               24   \n",
       "\n",
       "    split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "17            0.999997            0.999996          0.999997     5.028113e-07  \n",
       "5             0.999996            0.999997          0.999996     3.661838e-07  \n",
       "4             0.999997            0.999996          0.999996     3.529083e-07  \n",
       "16            0.999995            0.999997          0.999996     6.781592e-07  \n",
       "15            1.000000            1.000000          1.000000     4.425182e-09  \n",
       "3             1.000000            1.000000          1.000000     4.978330e-09  \n",
       "2             1.000000            1.000000          1.000000     7.522810e-08  \n",
       "14            1.000000            1.000000          1.000000     7.467495e-08  \n",
       "23            0.999990            0.999990          0.999990     2.594263e-07  \n",
       "13            1.000000            1.000000          1.000000     0.000000e+00  \n",
       "11            0.999988            0.999989          0.999988     2.986998e-07  \n",
       "1             1.000000            1.000000          1.000000     4.425182e-09  \n",
       "21            0.999998            0.999999          0.999999     5.221715e-07  \n",
       "22            0.999989            0.999987          0.999988     8.075957e-07  \n",
       "9             0.999998            0.999999          0.999999     2.710424e-07  \n",
       "10            0.999984            0.999983          0.999983     5.028113e-07  \n",
       "12            1.000000            1.000000          1.000000     2.765739e-09  \n",
       "0             1.000000            1.000000          1.000000     1.106295e-09  \n",
       "20            0.999999            0.999999          0.999999     1.814325e-07  \n",
       "8             0.999998            0.999998          0.999998     1.216925e-08  \n",
       "19            1.000000            1.000000          1.000000     0.000000e+00  \n",
       "7             1.000000            1.000000          1.000000     5.476163e-08  \n",
       "18            1.000000            1.000000          1.000000     5.531477e-10  \n",
       "6             1.000000            1.000000          1.000000     3.650775e-08  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(rf_grid.cv_results_).sort_values(by='mean_test_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV iterations: 2\n",
      "AUC mean: 0.877\n",
      "AUC std: 0.002\n",
      "Wall time: 11min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Trying to do a bit better.\n",
    "score = 'roc_auc'\n",
    "Forest = RandomForestClassifier(n_estimators=1000, max_features=4, max_depth=100, min_samples_split=20, min_samples_leaf=10, bootstrap=True, random_state=0)\n",
    "ForestScores5 = cross_val_score(Forest, X_train, y_train, cv=2, n_jobs=-1, scoring=score)\n",
    "print(\"CV iterations: {}\\nAUC mean: {:.3f}\\nAUC std: {:.3f}\".format(len(ForestScores5), ForestScores5.mean(), ForestScores5.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Final forest model with predictions and submission (ForestScores5)#################\n",
    "Forest = RandomForestClassifier(n_estimators=1000, max_features=4, max_depth=100, min_samples_split=20, min_samples_leaf=10, bootstrap=True, random_state=0)\n",
    "ForestModel = Forest.fit(X_train, y_train)\n",
    "y_pred = ForestModel.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "###################################Logistic regression#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Custom transformer for feature engineering.\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):          \n",
    "    #Class Constructor \n",
    "    def __init__(self, agg=1):\n",
    "        self.agg = agg\n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform(self, X, y = None):\n",
    "        X = pd.DataFrame(X)\n",
    "        if self.agg == 1:\n",
    "            return X.values\n",
    "        elif self.agg == 2:\n",
    "            idx =  X.columns.values[2:202]             \n",
    "            X['sum'] = X[idx].sum(axis=1)  \n",
    "            X['min'] = X[idx].min(axis=1)\n",
    "            X['max'] = X[idx].max(axis=1)\n",
    "            X['mean'] = X[idx].mean(axis=1)\n",
    "            X['std'] = X[idx].std(axis=1)\n",
    "            X['skew'] = X[idx].skew(axis=1)\n",
    "            X['kurt'] = X[idx].kurtosis(axis=1)\n",
    "            X['med'] = X[idx].median(axis=1)\n",
    "            return X.values\n",
    "        elif self.agg == 3:\n",
    "            idx =  X.columns.values[2:202]\n",
    "            X['sum'] = X[idx].sum(axis=1)  \n",
    "            X['min'] = X[idx].min(axis=1)\n",
    "            X['max'] = X[idx].max(axis=1)\n",
    "            X['mean'] = X[idx].mean(axis=1)\n",
    "            X['std'] = X[idx].std(axis=1)\n",
    "            X['skew'] = X[idx].skew(axis=1)\n",
    "            X['kurt'] = X[idx].kurtosis(axis=1)\n",
    "            X['med'] = X[idx].median(axis=1)\n",
    "            X = X.iloc[:,-8:]\n",
    "            return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), \n",
    "                 ('featureengineering', FeatureEngineering(agg=2)),\n",
    "                 ('classifier', LogisticRegression(C=10, max_iter=1000, random_state=0, solver='sag'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "roc_auc_score(y_test, pipe.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sag is supposed to be faster for bigger datasets. However, it failed to converge with the default iteration of 100.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C=[.01, .1, 1.0, 10]\n",
    "solver='sag',\n",
    "log_param_grid = {'C': C,\n",
    "                  'solver': solver,\n",
    "                  'max_iter': [1000]}\n",
    "display(log_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  16 | elapsed: 13.1min remaining:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed: 17.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Note sure sag is saving time. I didn't try the default.\n",
    "%%time\n",
    "score = 'roc_auc'\n",
    "logreg = LogisticRegression()\n",
    "log_grid = GridSearchCV(estimator = logreg, param_grid = log_param_grid, \n",
    "                       cv = 4, n_jobs = -1, verbose = 2, scoring = score)\n",
    "log_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8589207492206489"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'max_iter': 1000, 'solver': 'sag'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_grid.best_score_\n",
    "log_grid.best_params_\n",
    "#log_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>445.169238</td>\n",
       "      <td>2.747545</td>\n",
       "      <td>0.035933</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 10, 'max_iter': 1000, 'solver': 'sag'}</td>\n",
       "      <td>0.853232</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864499</td>\n",
       "      <td>0.858921</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862906</td>\n",
       "      <td>0.861501</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>0.859271</td>\n",
       "      <td>0.861045</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>569.194663</td>\n",
       "      <td>0.870682</td>\n",
       "      <td>0.043544</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 1.0, 'max_iter': 1000, 'solver': 'sag'}</td>\n",
       "      <td>0.853202</td>\n",
       "      <td>0.857554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864487</td>\n",
       "      <td>0.858893</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>2</td>\n",
       "      <td>0.862877</td>\n",
       "      <td>0.861471</td>\n",
       "      <td>0.860474</td>\n",
       "      <td>0.859240</td>\n",
       "      <td>0.861016</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>574.151204</td>\n",
       "      <td>3.182388</td>\n",
       "      <td>0.172929</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 1000, 'solver': 'sag'}</td>\n",
       "      <td>0.852913</td>\n",
       "      <td>0.857315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864309</td>\n",
       "      <td>0.858609</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>3</td>\n",
       "      <td>0.862588</td>\n",
       "      <td>0.861180</td>\n",
       "      <td>0.860223</td>\n",
       "      <td>0.858927</td>\n",
       "      <td>0.860730</td>\n",
       "      <td>0.001338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215.111313</td>\n",
       "      <td>2.580298</td>\n",
       "      <td>0.169311</td>\n",
       "      <td>0.013140</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 1000, 'solver': 'sag'}</td>\n",
       "      <td>0.851654</td>\n",
       "      <td>0.856365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863157</td>\n",
       "      <td>0.857400</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>4</td>\n",
       "      <td>0.861363</td>\n",
       "      <td>0.859937</td>\n",
       "      <td>0.859121</td>\n",
       "      <td>0.857636</td>\n",
       "      <td>0.859514</td>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "3     445.169238      2.747545         0.035933        0.003786      10   \n",
       "2     569.194663      0.870682         0.043544        0.001880       1   \n",
       "1     574.151204      3.182388         0.172929        0.051861     0.1   \n",
       "0     215.111313      2.580298         0.169311        0.013140    0.01   \n",
       "\n",
       "  param_max_iter param_solver                                          params  \\\n",
       "3           1000          sag    {'C': 10, 'max_iter': 1000, 'solver': 'sag'}   \n",
       "2           1000          sag   {'C': 1.0, 'max_iter': 1000, 'solver': 'sag'}   \n",
       "1           1000          sag   {'C': 0.1, 'max_iter': 1000, 'solver': 'sag'}   \n",
       "0           1000          sag  {'C': 0.01, 'max_iter': 1000, 'solver': 'sag'}   \n",
       "\n",
       "   split0_test_score  split1_test_score       ...         split3_test_score  \\\n",
       "3           0.853232           0.857573       ...                  0.864499   \n",
       "2           0.853202           0.857554       ...                  0.864487   \n",
       "1           0.852913           0.857315       ...                  0.864309   \n",
       "0           0.851654           0.856365       ...                  0.863157   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "3         0.858921        0.004105                1            0.862906   \n",
       "2         0.858893        0.004109                2            0.862877   \n",
       "1         0.858609        0.004132                3            0.862588   \n",
       "0         0.857400        0.004132                4            0.861363   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "3            0.861501            0.860500            0.859271   \n",
       "2            0.861471            0.860474            0.859240   \n",
       "1            0.861180            0.860223            0.858927   \n",
       "0            0.859937            0.859121            0.857636   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "3          0.861045         0.001334  \n",
       "2          0.861016         0.001334  \n",
       "1          0.860730         0.001338  \n",
       "0          0.859514         0.001349  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(log_grid.cv_results_).sort_values(by='mean_test_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "###################################Gradient boosted tree#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [450, 550],\n",
       " 'learning_rate': [2, 1, 0.01],\n",
       " 'max_depth': [1, 2]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Grid search.\n",
    "n_estimators=[450, 550]\n",
    "learning_rate=[2, 1, .01]\n",
    "max_depth=[1, 2]\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_depth': max_depth}\n",
    "display(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed: 68.1min remaining:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 70.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [450, 550], 'learning_rate': [2, 1, 0.01], 'max_depth': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score='roc_auc'\n",
    "gbc = GradientBoostingClassifier()\n",
    "rf_grid = GridSearchCV(estimator = gbc, param_grid = param_grid, cv = 2, scoring = score, verbose=2, n_jobs = -1)\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8816425550090435"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'max_depth': 1, 'n_estimators': 550}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_score_\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "###################################Adaboost#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV iterations: 2\n",
      "AUC mean: 0.877\n",
      "AUC std: 0.000\n",
      "Wall time: 19min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = 'roc_auc'\n",
    "ada = AdaBoostClassifier(n_estimators=350, learning_rate=1, random_state=0) \n",
    "adaScores4 = cross_val_score(ada, X_train, y_train, cv=2, n_jobs=-1, scoring=score)\n",
    "print(\"CV iterations: {}\\nAUC mean: {:.3f}\\nAUC std: {:.3f}\".format(len(adaScores4), adaScores4.mean(), adaScores4.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = 'roc_auc'\n",
    "ada = AdaBoostClassifier(n_estimators=500, learning_rate=1, random_state=0) \n",
    "ada_fit = ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adamodel_fit_350.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the model.\n",
    "# Output a pickle file for the model\n",
    "joblib.dump(ada_fit, 'adamodel_fit_350.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "ada_load = joblib.load('adamodel_fit_350.pkl') \n",
    " \n",
    "# Check that the loaded model is the same as the original\n",
    "assert ada.score(X_train, y_train) == ada_load.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################XGboost#####################################################\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 500, random_state=42)\n",
    "xgb.fit = xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgbmodel_fit_350.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the model.\n",
    "# Output a pickle file for the model\n",
    "joblib.dump(xgb.fit, 'xgbmodel_fit_350.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "xgb_load = joblib.load('xgbmodel_fit_350.pkl') \n",
    " \n",
    "# Check that the loaded model is the same as the original\n",
    "assert xgb.score(X_train, y_train) == xgb_load.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucList = []\n",
    "fpr, tpr, thr = roc_curve(y_test, ada_load.predict_proba(X_test)[:,1])\n",
    "aucList.append(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label='adaboost')\n",
    "fpr, tpr, thr = roc_curve(y_test, xgb_load.predict_proba(X_test)[:,1])\n",
    "aucList.append(auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, label='xgbboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################All Tuned Models#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Curt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160b9f6aac8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160b9f74518>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160ba44dc50>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160ba5ea668>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160ba19b048>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x160ba19bc18>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x160aa209748>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'False Positive Rate')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'True Positive Rate')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Receiver Operating Characteristic Plot')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Log</td>\n",
       "      <td>0.858876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.653011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest</td>\n",
       "      <td>0.876505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>0.888013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.884841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.884671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  AUC Score\n",
       "0            Log   0.858876\n",
       "1           Tree   0.653011\n",
       "2         Forest   0.876505\n",
       "3  GradientBoost   0.888013\n",
       "4       AdaBoost   0.884841\n",
       "5        XGBoost   0.884671"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I think I need to split into train and test first to avoid just giving AUC curves for the training data itself.\n",
    "#%%time\n",
    "classifiers = [\n",
    "    #(\"NaiveBayes\", GaussianNB()),\n",
    "    #(\"svc\", SVC(random_state=0)),   \n",
    "    #(\"per\", Perceptron())        Doesn't work because no .predict_proba\n",
    "    #(\"knn\", KNeighborsClassifier(n_neighbors=3)    Takes too long\n",
    "    (\"Log\", LogisticRegression(C=10, max_iter=1000, random_state=0, solver='sag')),\n",
    "    #(\"ridge\", Ridge(alpha=0.5, max_iter=None, normalize=True, random_state=0, solver='auto', tol=0.001)),\n",
    "    #(\"lasso\", Lasso(alpha=0.001, max_iter=100000,normalize=True, random_state=0, tol=0.0001)),\n",
    "    #(\"sgd\", SGDClassifier(loss='log', random_state=0)),\n",
    "    \n",
    "    (\"Tree\", DecisionTreeClassifier(max_depth=8, random_state=0)),\n",
    "    (\"Forest\", RandomForestClassifier(n_estimators=1000, max_features=4, max_depth=100, min_samples_split=20, min_samples_leaf=10, bootstrap=True, random_state=0)),\n",
    "    (\"GradientBoost\", GradientBoostingClassifier(n_estimators=600, max_depth=1, learning_rate=1, random_state=0)),\n",
    "    (\"AdaBoost\", AdaBoostClassifier(n_estimators=350, learning_rate=1, random_state=0)), \n",
    "    (\"XGBoost\", xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators = 500, random_state=42))\n",
    "]\n",
    "\n",
    "modelNameList = []\n",
    "aucList = []\n",
    "cvMeanList = []\n",
    "cvSTDList = []\n",
    "     \n",
    "for name, clf in classifiers:\n",
    "    modelNameList.append(name)\n",
    "     \n",
    "    fitted = clf.fit(X_train, y_train)\n",
    "    fpr, tpr, thr = roc_curve(y_test, fitted.predict_proba(X_test)[:,1])\n",
    "    aucList.append(auc(fpr, tpr))\n",
    "    \n",
    "    plt.plot(fpr, tpr, label=name)\n",
    "    \n",
    "    #rng = np.random.RandomState(42)\n",
    "    #cvScores = cross_val_score(clf, X_train, y_train, scoring='roc_auc', cv=4, n_jobs = -1) \n",
    "    #cvMean = cvScores.mean()\n",
    "    #cvMeanList.append(cvMean)\n",
    "    #cvSTD = cvScores.std()                           \n",
    "    #cvSTDList.append(cvSTD)\n",
    "     \n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Plot')\n",
    "   \n",
    "ModelResultsSummary = pd.DataFrame()\n",
    "ModelResultsSummary['Model'] = modelNameList\n",
    "ModelResultsSummary['AUC Score'] = aucList\n",
    "#ModelResultsSummary['AUC Score_Cross Validation'] = cvMeanList\n",
    "#ModelResultsSummary['AUC STD_Cross Validation'] = cvSTDList\n",
    "#ModelResultsSummary.sort_values(by='AUC Score_Cross Validation', ascending=False).reset_index(drop=True)\n",
    "display(ModelResultsSummary)\n",
    "#Code from here helped: https://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_comparison.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
